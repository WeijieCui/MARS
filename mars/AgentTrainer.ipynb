{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from mars.utils import merge_bounding_box\n",
    "import os\n",
    "import numpy as np\n",
    "from mars.env import SearchEnv\n",
    "from mars.detector import YoloV11Detector\n",
    "from mars.AgentQTableTrainer import DotaRawDataset\n",
    "from mars.agent import RLQtableAgent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "episodes = 8\n",
    "log_interval = 1\n",
    "agent = RLQtableAgent(training=True, load=True)\n",
    "train_dataset = DotaRawDataset(\n",
    "    # image_dir=os.path.join('../data/train', 'images'),\n",
    "    # label_dir=os.path.join('../data/train', 'labelTxt')\n",
    "    image_dir=os.path.join('\\\\Data\\\\train', 'images'),\n",
    "    label_dir=os.path.join('\\\\Data\\\\train', 'labelTxt')\n",
    ")\n",
    "\n",
    "env = SearchEnv()\n",
    "env.set_detector(YoloV11Detector())\n",
    "\n",
    "# 用于绘图的列表\n",
    "episode_rewards = []\n",
    "episode_vehicles_found = []\n",
    "episode_steps = []\n",
    "moving_avg_rewards = []\n",
    "moving_avg_found = []\n",
    "\n",
    "for episode in range(episodes):\n",
    "    vehicles_found_this_episode = 0\n",
    "    total_reward = 0\n",
    "    image_steps = []\n",
    "    for image, target in train_dataset:\n",
    "        env.set_image(image)\n",
    "        env.set_all_target(target)\n",
    "        status = env.reset()\n",
    "        image_reward = 0\n",
    "        done = False\n",
    "        all_obbs = []\n",
    "        step = 0\n",
    "        steps_count = 0\n",
    "        obbs = []\n",
    "        for step in range(10):\n",
    "            # 选择动作\n",
    "            action = agent.select_action(*status)\n",
    "            if not action:\n",
    "                break\n",
    "            # 执行动作\n",
    "            next_status, reward, obbs, window = env.step(action)\n",
    "            merge_bounding_box(all_obbs, obbs)\n",
    "            # 学习\n",
    "            agent.update(status, action, reward, next_status)\n",
    "            status = next_status\n",
    "            image_reward += reward\n",
    "        # 记录本轮指标\n",
    "        steps_count += step\n",
    "        total_reward += image_reward\n",
    "        episode_steps.append(steps_count)\n",
    "        vehicles_found_this_episode += len(all_obbs)\n",
    "    episode_rewards.append(total_reward)\n",
    "    episode_vehicles_found.append(vehicles_found_this_episode)\n",
    "\n",
    "    # 计算滑动平均（窗口大小为100）以便更容易看到趋势\n",
    "    moving_avg_r = np.mean(episode_rewards[-100:]) if len(episode_rewards) >= 100 else np.mean(episode_rewards)\n",
    "    moving_avg_rewards.append(moving_avg_r)\n",
    "    moving_avg_f = np.mean(episode_vehicles_found[-100:]) if len(episode_vehicles_found) >= 100 else np.mean(\n",
    "        episode_vehicles_found)\n",
    "    moving_avg_found.append(moving_avg_f)\n",
    "\n",
    "    # 定期打印日志\n",
    "    print(f\"Episode {episode:4d}/{episodes} | \"\n",
    "          f\"Reward: {total_reward:6.1f} | \"\n",
    "          f\"Vehicles Found: {vehicles_found_this_episode:2d} | \"\n",
    "          f\"Steps: {episode_steps} | \"\n",
    "          f\"Avg Reward (MA100): {moving_avg_r:6.1f} | \"\n",
    "          f\"Avg Found (MA100): {moving_avg_f:4.1f}\")\n",
    "    agent.save('qtable-{}.pkl'.format(episode))\n",
    "# 训练结束后绘制图表\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(episode_vehicles_found, label='Per Episode', alpha=0.3)\n",
    "plt.plot(moving_avg_found, label='Moving Avg (100)', linewidth=2)\n",
    "plt.axhline(y=100, color='r', linestyle='--', label='True Count')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Vehicles Found')\n",
    "plt.title('Performance: Vehicles Found per Episode')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(episode_rewards, label='Per Episode', alpha=0.3)\n",
    "plt.plot(moving_avg_rewards, label='Moving Avg (100)', linewidth=2)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total Reward')\n",
    "plt.title('Performance: Total Reward per Episode')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(episode_steps)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Steps Taken')\n",
    "plt.title('Efficiency: Steps per Episode')\n",
    "plt.grid(True)\n",
    "\n",
    "# ... 你还可以添加Loss等图 ...\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_metrics.png')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a680fd9fc917886f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
